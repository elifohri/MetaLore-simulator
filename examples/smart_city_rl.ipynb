{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstrating `mobile-env:smart-city`\n",
    "\n",
    "`mobile-env` is a simple and open environment for training, testing, and evaluating a decentralized metaverse environment.\n",
    "\n",
    "* `mobile-env:smart-city` is written in pure Python\n",
    "* It allows simulating various scenarios with moving users in a cellular network with a single base station and multiple stationary sensors\n",
    "* `mobile-env:smart-city` implements the standard [Gymnasium](https://gymnasium.farama.org/) (previously [OpenAI Gym](https://gym.openai.com/)) interface such that it can be used with all common frameworks for reinforcement learning\n",
    "* `mobile-env:smart-city` is not restricted to reinforcement learning approaches but can also be used with conventional control approaches or dummy benchmark algorithms\n",
    "* It can be configured easily (e.g., adjusting number and movement of users, properties of cells, etc.)\n",
    "* It is also easy to extend `mobile-env:smart-city`, e.g., implementing different observations, actions, or reward\n",
    "\n",
    "As such `mobile-env:smart-city` is a simple platform to ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Demonstration Steps:**\n",
    "\n",
    "This demonstration consists of the following steps:\n",
    "\n",
    "1. Installation and usage of `mobile-env` with dummy actions\n",
    "2. Configuration of `mobile-env` and adjustment of the observation space (optional)\n",
    "3. Training a single-agent reinforcement learning approach with [`stable-baselines3`](https://github.com/DLR-RM/stable-baselines3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stable-baselines3==2.0.0 in c:\\users\\elifo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: tensorboard in c:\\users\\elifo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.17.1)\n",
      "Requirement already satisfied: gymnasium==0.28.1 in c:\\users\\elifo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from stable-baselines3==2.0.0) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\elifo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from stable-baselines3==2.0.0) (1.26.2)\n",
      "Requirement already satisfied: torch>=1.11 in c:\\users\\elifo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from stable-baselines3==2.0.0) (2.2.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\elifo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from stable-baselines3==2.0.0) (3.0.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\elifo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from stable-baselines3==2.0.0) (2.2.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\elifo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from stable-baselines3==2.0.0) (3.8.2)\n",
      "Requirement already satisfied: jax-jumpy>=1.0.0 in c:\\users\\elifo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gymnasium==0.28.1->stable-baselines3==2.0.0) (1.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\elifo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gymnasium==0.28.1->stable-baselines3==2.0.0) (4.8.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\elifo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gymnasium==0.28.1->stable-baselines3==2.0.0) (0.0.4)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\users\\elifo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gymnasium==0.28.1->stable-baselines3==2.0.0) (4.13.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\elifo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\elifo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard) (1.66.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\elifo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard) (3.7)\n",
      "Requirement already satisfied: packaging in c:\\users\\elifo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in c:\\users\\elifo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard) (4.25.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\elifo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard) (69.2.0)\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\elifo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\elifo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\elifo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard) (3.0.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\elifo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.11->stable-baselines3==2.0.0) (3.13.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\elifo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.11->stable-baselines3==2.0.0) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\elifo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.11->stable-baselines3==2.0.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\elifo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.11->stable-baselines3==2.0.0) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\elifo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.11->stable-baselines3==2.0.0) (2023.12.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\elifo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\elifo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->stable-baselines3==2.0.0) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\elifo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->stable-baselines3==2.0.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\elifo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->stable-baselines3==2.0.0) (4.44.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\elifo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->stable-baselines3==2.0.0) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\elifo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->stable-baselines3==2.0.0) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\elifo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->stable-baselines3==2.0.0) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\elifo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->stable-baselines3==2.0.0) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\elifo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->stable-baselines3==2.0.0) (6.1.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\elifo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->stable-baselines3==2.0.0) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\elifo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->stable-baselines3==2.0.0) (2023.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\elifo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from importlib-metadata>=4.8.0->gymnasium==0.28.1->stable-baselines3==2.0.0) (3.17.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\elifo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sympy->torch>=1.11->stable-baselines3==2.0.0) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# First, install stable baselines; only SB3 v2.0.0+ supports Gymnasium\n",
    "%pip install stable-baselines3==2.0.0 tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'width': 200,\n",
       " 'height': 200,\n",
       " 'EP_MAX_TIME': 100,\n",
       " 'seed': 666,\n",
       " 'reset_rng_episode': False,\n",
       " 'arrival': mobile_env.core.arrival.NoDeparture,\n",
       " 'channel': mobile_env.core.channels.OkumuraHata,\n",
       " 'scheduler': mobile_env.core.schedules.RoundRobin,\n",
       " 'movement': mobile_env.core.movement.RandomWaypointMovement,\n",
       " 'utility': mobile_env.core.utilities.BoundedLogUtility,\n",
       " 'handler': mobile_env.handlers.smart_city_handler.MComSmartCityHandler,\n",
       " 'bs': {'bw': 100000000.0,\n",
       "  'freq': 2500,\n",
       "  'tx': 40,\n",
       "  'height': 50,\n",
       "  'computational_power': 100},\n",
       " 'ue': {'velocity': 1.5, 'snr_tr': 2e-08, 'noise': 1e-09, 'height': 1.5},\n",
       " 'sensor': {'height': 1.5,\n",
       "  'snr_tr': 2e-08,\n",
       "  'noise': 1e-09,\n",
       "  'velocity': 0,\n",
       "  'radius': 500,\n",
       "  'logs': {}},\n",
       " 'ue_job': {'job_generation_probability': 0.7,\n",
       "  'communication_job_lambda_value': 2.875,\n",
       "  'computation_job_lambda_value': 10.0},\n",
       " 'sensor_job': {'communication_job_lambda_value': 1.125,\n",
       "  'computation_job_lambda_value': 5.0},\n",
       " 'e2e_delay_threshold': 5,\n",
       " 'reward_calculation': {'ue_penalty': -3,\n",
       "  'discount_factor': 0.9,\n",
       "  'base_reward': 10,\n",
       "  'positive_discount_factor': 0.9,\n",
       "  'negative_discount_factor': 0.8},\n",
       " 'arrival_params': {'ep_time': 100, 'reset_rng_episode': False},\n",
       " 'channel_params': {},\n",
       " 'scheduler_params': {'quantum': 2.0},\n",
       " 'movement_params': {'width': 200, 'height': 200, 'reset_rng_episode': False},\n",
       " 'utility_params': {'lower': -20, 'upper': 20, 'coeffs': (10, 0, 10)},\n",
       " 'metrics': {'scalar_metrics': {},\n",
       "  'ue_metrics': {},\n",
       "  'bs_metrics': {},\n",
       "  'ss_metrics': {}}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import gymnasium\n",
    "import mobile_env\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "# predefined small scenarios\n",
    "from mobile_env.scenarios.smart_city import MComSmartCity\n",
    "\n",
    "# easy access to the default configuration\n",
    "MComSmartCity.default_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium.envs.registration import register\n",
    "\n",
    "# Register the new environment\n",
    "register(\n",
    "    id='mobile-smart_city-smart_city_handler-rl-v0',\n",
    "    entry_point='mobile_env.scenarios.smart_city:MComSmartCity',  # Adjust this if the entry point is different\n",
    "    kwargs={'config': {}, 'render_mode': None}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['CartPole-v0', 'CartPole-v1', 'MountainCar-v0', 'MountainCarContinuous-v0', 'Pendulum-v1', 'Acrobot-v1', 'CartPoleJax-v0', 'CartPoleJax-v1', 'PendulumJax-v0', 'LunarLander-v2', 'LunarLanderContinuous-v2', 'BipedalWalker-v3', 'BipedalWalkerHardcore-v3', 'CarRacing-v2', 'Blackjack-v1', 'FrozenLake-v1', 'FrozenLake8x8-v1', 'CliffWalking-v0', 'Taxi-v3', 'Jax-Blackjack-v0', 'Reacher-v2', 'Reacher-v4', 'Pusher-v2', 'Pusher-v4', 'InvertedPendulum-v2', 'InvertedPendulum-v4', 'InvertedDoublePendulum-v2', 'InvertedDoublePendulum-v4', 'HalfCheetah-v2', 'HalfCheetah-v3', 'HalfCheetah-v4', 'Hopper-v2', 'Hopper-v3', 'Hopper-v4', 'Swimmer-v2', 'Swimmer-v3', 'Swimmer-v4', 'Walker2d-v2', 'Walker2d-v3', 'Walker2d-v4', 'Ant-v2', 'Ant-v3', 'Ant-v4', 'Humanoid-v2', 'Humanoid-v3', 'Humanoid-v4', 'HumanoidStandup-v2', 'HumanoidStandup-v4', 'GymV21Environment-v0', 'GymV26Environment-v0', 'mobile-smart_city-smart_city_handler-v0', 'mobile-smart_city-smart_city_handler-rl-v0'])\n",
      "Environment 'mobile-smart_city-smart_city_handler-rl-v0' registered successfully!\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "# List all registered environments\n",
    "env_specs = gym.envs.registry.keys()\n",
    "print(env_specs)\n",
    "\n",
    "# Verify your specific environment is listed\n",
    "assert 'mobile-smart_city-smart_city_handler-rl-v0' in env_specs, \"Environment not registered correctly\"\n",
    "print(\"Environment 'mobile-smart_city-smart_city_handler-rl-v0' registered successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Smart city environment for RL with 5 users, 10 sensors and 1 cells.\n"
     ]
    }
   ],
   "source": [
    "# create a small mobile environment for a single, centralized control agent\n",
    "# pass rgb_array as render mode so the env can be rendered inside the notebook\n",
    "env = gymnasium.make(\"mobile-smart_city-smart_city_handler-rl-v0\", render_mode=\"rgb_array\")\n",
    "\n",
    "print(f\"\\nSmart city environment for RL with {env.NUM_USERS} users, {env.NUM_SENSORS} sensors and {env.NUM_STATIONS} cells.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to results_sb\\PPO_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\git-clones\\metaverse\\mobile-env\\mobile_env\\core\\job_generator.py:100: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self.packet_df_ue = pd.concat([self.packet_df_ue, packet_df], ignore_index=True)\n",
      "c:\\git-clones\\metaverse\\mobile-env\\mobile_env\\core\\job_generator.py:98: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self.packet_df_sensor = pd.concat([self.packet_df_sensor, packet_df], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Train a Single-Agent Reinforcement Learning Approach\n",
    "\n",
    "import os\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import EvalCallback, CheckpointCallback\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "# Define the model for training (PPO algorithm)\n",
    "model = PPO(MlpPolicy, env, tensorboard_log='results_sb', verbose=1)\n",
    "\n",
    "# Callback: Save a checkpoint of the model at regular intervals\n",
    "checkpoint_callback = CheckpointCallback(save_freq=10000, save_path='./checkpoints/',\n",
    "                                         name_prefix='ppo_model_checkpoint')\n",
    "\n",
    "# Callback: Evaluate the model every 5000 timesteps and log the results\n",
    "eval_callback = EvalCallback(env, best_model_save_path='./logs/best_model',\n",
    "                             log_path='./logs/', eval_freq=500,\n",
    "                             deterministic=True, render=False)\n",
    "\n",
    "# Train the model for a set number of timesteps (modify to suit your needs)\n",
    "model.learn(total_timesteps=100)\n",
    "\n",
    "# Save the trained model for future use\n",
    "model.save(\"ppo_mobile_env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Test the Trained Model\n",
    "\n",
    "# Load the saved model\n",
    "model = PPO.load(\"ppo_mobile_env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Test the model in the environment\n",
    "\n",
    "obs = env.reset()\n",
    "for step in range(200):\n",
    "    # Use the trained model to predict the action\n",
    "    action, _states = model.predict(obs)\n",
    "    \n",
    "    # Take the action in the environment\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    \n",
    "    # Print observation and reward\n",
    "    print(f\"Step {step+1} | Action: {action} | Observation: {obs} | Reward: {reward}\")\n",
    "    \n",
    "    # Break the loop if the episode is finished\n",
    "    if done:\n",
    "        print(\"Episode finished\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Plot Results (Optional)\n",
    "\n",
    "# Example of plotting some metrics (assuming the environment logs metrics like rewards, delays, etc.)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example plotting of dummy reward over episodes (assuming we have a list of rewards)\n",
    "# This is just an illustrative example - you'll need to replace this with your own logic for recording rewards\n",
    "rewards = [np.random.uniform(-1, 1) for _ in range(100)]  # Replace with actual data\n",
    "\n",
    "plt.plot(rewards)\n",
    "plt.title(\"Reward Over Episodes\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
