{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL Based Scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customized gymnasium environment: `smart-city`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, are some configurations for setting up a simulation environment for a mobile communication scenario in a smart city context using the Gymnasium library. It involves some basic imports, steps for registering the custom environment and creating a new instance of that environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Ray RLlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stable-baselines3[extra] in c:\\users\\bazzi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: gymnasium==0.28.1 in c:\\users\\bazzi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from stable-baselines3[extra]) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\bazzi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from stable-baselines3[extra]) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.11 in c:\\users\\bazzi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from stable-baselines3[extra]) (2.3.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\bazzi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from stable-baselines3[extra]) (3.0.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\bazzi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from stable-baselines3[extra]) (2.2.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\bazzi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from stable-baselines3[extra]) (3.8.4)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\bazzi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from stable-baselines3[extra]) (4.9.0.80)\n",
      "Requirement already satisfied: tensorboard>=2.9.1 in c:\\users\\bazzi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from stable-baselines3[extra]) (2.16.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\bazzi\\appdata\\roaming\\python\\python312\\site-packages (from stable-baselines3[extra]) (5.9.8)\n",
      "Collecting tqdm (from stable-baselines3[extra])\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.6 kB ? eta -:--:--\n",
      "     -------------------- ----------------- 30.7/57.6 kB 435.7 kB/s eta 0:00:01\n",
      "     -------------------------------------- 57.6/57.6 kB 599.5 kB/s eta 0:00:00\n",
      "Requirement already satisfied: rich in c:\\users\\bazzi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from stable-baselines3[extra]) (13.7.1)\n",
      "Collecting shimmy~=0.2.1 (from shimmy[atari]~=0.2.1; extra == \"extra\"->stable-baselines3[extra])\n",
      "  Downloading Shimmy-0.2.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: pillow in c:\\users\\bazzi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from stable-baselines3[extra]) (10.3.0)\n",
      "Collecting autorom~=0.6.0 (from autorom[accept-rom-license]~=0.6.0; extra == \"extra\"->stable-baselines3[extra])\n",
      "  Downloading AutoROM-0.6.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: pygame in c:\\users\\bazzi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from stable-baselines3[extra]) (2.5.2)\n",
      "Requirement already satisfied: jax-jumpy>=1.0.0 in c:\\users\\bazzi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gymnasium==0.28.1->stable-baselines3[extra]) (1.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\bazzi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gymnasium==0.28.1->stable-baselines3[extra]) (4.11.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\bazzi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gymnasium==0.28.1->stable-baselines3[extra]) (0.0.4)\n",
      "Requirement already satisfied: click in c:\\users\\bazzi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from autorom~=0.6.0->autorom[accept-rom-license]~=0.6.0; extra == \"extra\"->stable-baselines3[extra]) (8.1.7)\n",
      "Requirement already satisfied: requests in c:\\users\\bazzi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from autorom~=0.6.0->autorom[accept-rom-license]~=0.6.0; extra == \"extra\"->stable-baselines3[extra]) (2.31.0)\n",
      "Collecting AutoROM.accept-rom-license (from autorom[accept-rom-license]~=0.6.0; extra == \"extra\"->stable-baselines3[extra])\n",
      "  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n",
      "     ---------------------------------------- 0.0/434.7 kB ? eta -:--:--\n",
      "     ------------------------ ------------- 276.5/434.7 kB 8.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- 434.7/434.7 kB 9.0 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "INFO: pip is looking at multiple versions of shimmy[atari] to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting stable-baselines3[extra]\n",
      "  Using cached stable_baselines3-2.3.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting shimmy~=1.3.0 (from shimmy[atari]~=1.3.0; extra == \"extra\"->stable-baselines3[extra])\n",
      "  Downloading Shimmy-1.3.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting stable-baselines3[extra]\n",
      "  Downloading stable_baselines3-2.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "  Downloading stable_baselines3-2.1.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting shimmy~=1.1.0 (from shimmy[atari]~=1.1.0; extra == \"extra\"->stable-baselines3[extra])\n",
      "  Downloading Shimmy-1.1.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting stable-baselines3[extra]\n",
      "  Using cached stable_baselines3-2.0.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "  Downloading stable_baselines3-1.8.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting gym==0.21 (from stable-baselines3[extra])\n",
      "  Downloading gym-0.21.0.tar.gz (1.5 MB)\n",
      "     ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "     ----------- ---------------------------- 0.4/1.5 MB 13.9 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 1.1/1.5 MB 14.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.5/1.5 MB 14.1 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Getting requirements to build wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [3 lines of output]\n",
      "      C:\\Users\\Bazzi\\AppData\\Local\\Temp\\pip-build-env-3hj2xrlg\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\dist.py:261: UserWarning: Unknown distribution option: 'tests_require'\n",
      "        warnings.warn(msg)\n",
      "      error in gym setup command: 'extras_require' must be a dictionary whose values are strings or lists of strings containing valid project/version requirement specifiers.\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "× Getting requirements to build wheel did not run successfully.\n",
      "│ exit code: 1\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install stable-baselines3[extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# predefined small scenarios\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmobile_env\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscenarios\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msmart_city\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MComSmartCity\n\u001b[1;32m----> 6\u001b[0m env \u001b[38;5;241m=\u001b[39m MComSmartCity(\u001b[43mstations\u001b[49m, users, sensors, config)\n\u001b[0;32m      7\u001b[0m check_env(env)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stations' is not defined"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.env_checker import check_env\n",
    "import mobile_env\n",
    "# predefined small scenarios\n",
    "from mobile_env.scenarios.smart_city import MComSmartCity\n",
    "from mobile_env.\n",
    "env = MComSmartCity(stations, users, sensors, config)\n",
    "check_env(env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\elifo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-09-11 10:16:47,346\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-09-11 10:16:48,371\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import gymnasium\n",
    "from ray.tune.registry import register_env\n",
    "\n",
    "# use the mobile-env RLlib wrapper for RLlib\n",
    "def register(config):\n",
    "    # importing mobile_env registers the included environments\n",
    "    import mobile_env\n",
    "    from mobile_env.wrappers.multi_agent import RLlibMAWrapper\n",
    "\n",
    "    env = gymnasium.make(\"mobile-smart_city-smart_city_handler-ma-v0\")\n",
    "    return RLlibMAWrapper(env)\n",
    "\n",
    "# register the predefined scenario with RLlib\n",
    "register_env(\"mobile-smart_city-smart_city_handler-ma-v0\", register)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a PPO Multi-Agent Policy\n",
    "\n",
    "Now, that the predefined scenario is registered with RLlib, we can configure and train a multi-agent PPO approach on the scenario with RLlib."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import ray\n",
    "\n",
    "\n",
    "# init ray with available CPUs (and GPUs) and init ray\n",
    "ray.init(\n",
    "  num_cpus=2,   # change to your available number of CPUs\n",
    "  include_dashboard=False,\n",
    "  ignore_reinit_error=True,\n",
    "  log_to_driver=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-11 10:16:53,154\tWARNING deprecation.py:50 -- DeprecationWarning: `AlgorithmConfig.resources(num_cpus_per_worker)` has been deprecated. Use `AlgorithmConfig.env_runners(num_cpus_per_env_runner)` instead. This will raise an error in the future!\n",
      "2024-09-11 10:16:53,156\tWARNING deprecation.py:50 -- DeprecationWarning: `rollouts` has been deprecated. Use `AlgorithmConfig.env_runners(..)` instead. This will raise an error in the future!\n",
      "2024-09-11 10:16:53,156\tWARNING deprecation.py:50 -- DeprecationWarning: `AlgorithmConfig.env_runners(num_rollout_workers)` has been deprecated. Use `AlgorithmConfig.env_runners(num_env_runners)` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "ename": "ArrowInvalid",
     "evalue": "URI has empty scheme: './results_rllib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 22\u001b[0m\n\u001b[0;32m      8\u001b[0m config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m      9\u001b[0m     PPOConfig()\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;241m.\u001b[39menvironment(env\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmobile-smart_city-smart_city_handler-ma-v0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;241m.\u001b[39mrollouts(num_rollout_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     19\u001b[0m )\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Create the Trainer/Tuner and define how long to train\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m tuner \u001b[38;5;241m=\u001b[39m \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtune\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTuner\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPPO\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mair\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRunConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Save the training progress and checkpoints locally under the specified subfolder.\u001b[39;49;00m\n\u001b[0;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./results_rllib\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Control training length by setting the number of iterations. 1 iter = 4000 time steps by default.\u001b[39;49;00m\n\u001b[0;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMaximumIterationStopper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mair\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCheckpointConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_at_end\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparam_space\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Run training and save the result\u001b[39;00m\n\u001b[0;32m     35\u001b[0m result_grid \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mfit()\n",
      "File \u001b[1;32mc:\\Users\\elifo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ray\\tune\\tuner.py:164\u001b[0m, in \u001b[0;36mTuner.__init__\u001b[1;34m(self, trainable, param_space, tune_config, run_config, _tuner_kwargs, _tuner_internal, _entrypoint)\u001b[0m\n\u001b[0;32m    162\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mpop(_SELF, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_ray_client:\n\u001b[1;32m--> 164\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_local_tuner \u001b[38;5;241m=\u001b[39m TunerInternal(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_remote_tuner \u001b[38;5;241m=\u001b[39m _force_on_current_node(\n\u001b[0;32m    167\u001b[0m         ray\u001b[38;5;241m.\u001b[39mremote(num_cpus\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)(TunerInternal)\n\u001b[0;32m    168\u001b[0m     )\u001b[38;5;241m.\u001b[39mremote(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\elifo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ray\\tune\\impl\\tuner_internal.py:138\u001b[0m, in \u001b[0;36mTunerInternal.__init__\u001b[1;34m(self, restore_path, storage_filesystem, resume_config, trainable, param_space, tune_config, run_config, _tuner_kwargs, _entrypoint)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_config\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_config\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m StorageContext\u001b[38;5;241m.\u001b[39mget_experiment_dir_name(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconverted_trainable)\n\u001b[0;32m    134\u001b[0m )\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m# The storage context here is only used to access the resolved\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# storage fs and experiment path, in order to avoid duplicating that logic.\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;66;03m# This is NOT the storage context object that gets passed to remote workers.\u001b[39;00m\n\u001b[1;32m--> 138\u001b[0m storage \u001b[38;5;241m=\u001b[39m \u001b[43mStorageContext\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperiment_dir_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_filesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_filesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m fs \u001b[38;5;241m=\u001b[39m storage\u001b[38;5;241m.\u001b[39mstorage_filesystem\n\u001b[0;32m    145\u001b[0m fs\u001b[38;5;241m.\u001b[39mcreate_dir(storage\u001b[38;5;241m.\u001b[39mexperiment_fs_path)\n",
      "File \u001b[1;32mc:\\Users\\elifo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ray\\train\\_internal\\storage.py:444\u001b[0m, in \u001b[0;36mStorageContext.__init__\u001b[1;34m(self, storage_path, experiment_dir_name, sync_config, storage_filesystem, trial_dir_name, current_checkpoint_index)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_checkpoint_index \u001b[38;5;241m=\u001b[39m current_checkpoint_index\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msync_config \u001b[38;5;241m=\u001b[39m sync_config \u001b[38;5;129;01mor\u001b[39;00m SyncConfig()\n\u001b[1;32m--> 444\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_filesystem, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_fs_path \u001b[38;5;241m=\u001b[39m \u001b[43mget_fs_and_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_filesystem\u001b[49m\n\u001b[0;32m    446\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_fs_path \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_fs_path)\u001b[38;5;241m.\u001b[39mas_posix()\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msyncer: Syncer \u001b[38;5;241m=\u001b[39m _FilesystemSyncer(\n\u001b[0;32m    450\u001b[0m     storage_filesystem\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_filesystem,\n\u001b[0;32m    451\u001b[0m     sync_period\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msync_config\u001b[38;5;241m.\u001b[39msync_period,\n\u001b[0;32m    452\u001b[0m     sync_timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msync_config\u001b[38;5;241m.\u001b[39msync_timeout,\n\u001b[0;32m    453\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\elifo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ray\\train\\_internal\\storage.py:309\u001b[0m, in \u001b[0;36mget_fs_and_path\u001b[1;34m(storage_path, storage_filesystem)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m storage_filesystem:\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m storage_filesystem, storage_path\n\u001b[1;32m--> 309\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpyarrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFileSystem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\elifo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyarrow\\_fs.pyx:477\u001b[0m, in \u001b[0;36mpyarrow._fs.FileSystem.from_uri\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\elifo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyarrow\\error.pxi:155\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\elifo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyarrow\\error.pxi:92\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mArrowInvalid\u001b[0m: URI has empty scheme: './results_rllib'"
     ]
    }
   ],
   "source": [
    "import ray.air\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "\n",
    "from ray.rllib.policy.policy import PolicySpec\n",
    "from ray.tune.stopper import MaximumIterationStopper\n",
    "\n",
    "# Create an RLlib config using multi-agent PPO on mobile-env's smart city scenario.\n",
    "config = (\n",
    "    PPOConfig()\n",
    "    .environment(env=\"mobile-smart_city-smart_city_handler-ma-v0\")\n",
    "    # Here, we configure all agents to share the same policy.\n",
    "    .multi_agent(\n",
    "        policies={\"shared_policy\": PolicySpec()},\n",
    "        policy_mapping_fn=lambda agent_id, episode, worker, **kwargs: \"shared_policy\",\n",
    "    )\n",
    "    # RLlib needs +1 CPU than configured below (for the driver/traininer?)\n",
    "    .resources(num_cpus_per_worker=1)\n",
    "    .rollouts(num_rollout_workers=1)\n",
    ")\n",
    "\n",
    "# Create the Trainer/Tuner and define how long to train\n",
    "tuner = ray.tune.Tuner(\n",
    "    \"PPO\",\n",
    "    run_config=ray.air.RunConfig(\n",
    "        # Save the training progress and checkpoints locally under the specified subfolder.\n",
    "        storage_path=\"./results_rllib\",\n",
    "        # Control training length by setting the number of iterations. 1 iter = 4000 time steps by default.\n",
    "        stop=MaximumIterationStopper(max_iter=10),\n",
    "        checkpoint_config=ray.air.CheckpointConfig(checkpoint_at_end=True),\n",
    "    ),\n",
    "    param_space=config,\n",
    ")\n",
    "\n",
    "# Run training and save the result\n",
    "result_grid = tuner.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
