{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstrating `mobile-env:smart-city`\n",
    "\n",
    "`mobile-env` is a simple and open environment for training, testing, and evaluating a decentralized metaverse environment.\n",
    "\n",
    "* `mobile-env:smart-city` is written in pure Python\n",
    "* It allows simulating various scenarios with moving users in a cellular network with a single base station and multiple stationary sensors\n",
    "* `mobile-env:smart-city` implements the standard [Gymnasium](https://gymnasium.farama.org/) (previously [OpenAI Gym](https://gym.openai.com/)) interface such that it can be used with all common frameworks for reinforcement learning\n",
    "* `mobile-env:smart-city` is not restricted to reinforcement learning approaches but can also be used with conventional control approaches or dummy benchmark algorithms\n",
    "* It can be configured easily (e.g., adjusting number and movement of users, properties of cells, etc.)\n",
    "* It is also easy to extend `mobile-env:smart-city`, e.g., implementing different observations, actions, or reward\n",
    "\n",
    "As such `mobile-env:smart-city` is a simple platform to test RL algorithms in a decentralized metaverse environment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Demonstration Steps:**\n",
    "\n",
    "This demonstration consists of the following steps:\n",
    "\n",
    "1. Installation and usage of `mobile-env` with dummy actions\n",
    "2. Configuration of `mobile-env` and adjustment of the observation space (optional)\n",
    "3. Training a single-agent reinforcement learning approach with [`stable-baselines3`](https://github.com/DLR-RM/stable-baselines3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: stable-baselines3==2.0.0 in /Users/elifohri/Library/Python/3.9/lib/python/site-packages (2.0.0)\n",
      "Requirement already satisfied: tensorboard in /Users/elifohri/Library/Python/3.9/lib/python/site-packages (2.18.0)\n",
      "Requirement already satisfied: torch>=1.11 in /Users/elifohri/Library/Python/3.9/lib/python/site-packages (from stable-baselines3==2.0.0) (2.5.1)\n",
      "Requirement already satisfied: cloudpickle in /Users/elifohri/Library/Python/3.9/lib/python/site-packages (from stable-baselines3==2.0.0) (3.1.0)\n",
      "Requirement already satisfied: pandas in /Users/elifohri/Library/Python/3.9/lib/python/site-packages (from stable-baselines3==2.0.0) (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.20 in /Users/elifohri/Library/Python/3.9/lib/python/site-packages (from stable-baselines3==2.0.0) (2.0.2)\n",
      "Requirement already satisfied: gymnasium==0.28.1 in /Users/elifohri/Library/Python/3.9/lib/python/site-packages (from stable-baselines3==2.0.0) (0.28.1)\n",
      "Requirement already satisfied: matplotlib in /Users/elifohri/Library/Python/3.9/lib/python/site-packages (from stable-baselines3==2.0.0) (3.9.3)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /Users/elifohri/Library/Python/3.9/lib/python/site-packages (from gymnasium==0.28.1->stable-baselines3==2.0.0) (0.0.4)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /Users/elifohri/Library/Python/3.9/lib/python/site-packages (from gymnasium==0.28.1->stable-baselines3==2.0.0) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /Users/elifohri/Library/Python/3.9/lib/python/site-packages (from gymnasium==0.28.1->stable-baselines3==2.0.0) (4.12.2)\n",
      "Requirement already satisfied: jax-jumpy>=1.0.0 in /Users/elifohri/Library/Python/3.9/lib/python/site-packages (from gymnasium==0.28.1->stable-baselines3==2.0.0) (1.0.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /Users/elifohri/Library/Python/3.9/lib/python/site-packages (from tensorboard) (1.68.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /Users/elifohri/Library/Python/3.9/lib/python/site-packages (from tensorboard) (2.1.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from tensorboard) (58.0.4)\n",
      "Requirement already satisfied: packaging in /Users/elifohri/Library/Python/3.9/lib/python/site-packages (from tensorboard) (24.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/elifohri/Library/Python/3.9/lib/python/site-packages (from tensorboard) (3.1.3)\n",
      "Requirement already satisfied: six>1.9 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from tensorboard) (1.15.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/elifohri/Library/Python/3.9/lib/python/site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /Users/elifohri/Library/Python/3.9/lib/python/site-packages (from tensorboard) (5.29.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/elifohri/Library/Python/3.9/lib/python/site-packages (from tensorboard) (3.7)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/elifohri/Library/Python/3.9/lib/python/site-packages (from importlib-metadata>=4.8.0->gymnasium==0.28.1->stable-baselines3==2.0.0) (3.21.0)\n",
      "Requirement already satisfied: networkx in /Users/elifohri/Library/Python/3.9/lib/python/site-packages (from torch>=1.11->stable-baselines3==2.0.0) (3.2.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/elifohri/Library/Python/3.9/lib/python/site-packages (from torch>=1.11->stable-baselines3==2.0.0) (1.13.1)\n",
      "Requirement already satisfied: jinja2 in /Users/elifohri/Library/Python/3.9/lib/python/site-packages (from torch>=1.11->stable-baselines3==2.0.0) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/elifohri/Library/Python/3.9/lib/python/site-packages (from torch>=1.11->stable-baselines3==2.0.0) (2024.10.0)\n",
      "Requirement already satisfied: filelock in /Users/elifohri/Library/Python/3.9/lib/python/site-packages (from torch>=1.11->stable-baselines3==2.0.0) (3.16.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/elifohri/Library/Python/3.9/lib/python/site-packages (from sympy==1.13.1->torch>=1.11->stable-baselines3==2.0.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/elifohri/Library/Python/3.9/lib/python/site-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/elifohri/Library/Python/3.9/lib/python/site-packages (from matplotlib->stable-baselines3==2.0.0) (4.55.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/elifohri/Library/Python/3.9/lib/python/site-packages (from matplotlib->stable-baselines3==2.0.0) (1.3.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/elifohri/Library/Python/3.9/lib/python/site-packages (from matplotlib->stable-baselines3==2.0.0) (1.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/elifohri/Library/Python/3.9/lib/python/site-packages (from matplotlib->stable-baselines3==2.0.0) (2.9.0.post0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/elifohri/Library/Python/3.9/lib/python/site-packages (from matplotlib->stable-baselines3==2.0.0) (0.12.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/elifohri/Library/Python/3.9/lib/python/site-packages (from matplotlib->stable-baselines3==2.0.0) (3.2.0)\n",
      "Requirement already satisfied: pillow>=8 in /Users/elifohri/Library/Python/3.9/lib/python/site-packages (from matplotlib->stable-baselines3==2.0.0) (11.0.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/elifohri/Library/Python/3.9/lib/python/site-packages (from matplotlib->stable-baselines3==2.0.0) (6.4.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/elifohri/Library/Python/3.9/lib/python/site-packages (from pandas->stable-baselines3==2.0.0) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/elifohri/Library/Python/3.9/lib/python/site-packages (from pandas->stable-baselines3==2.0.0) (2024.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# First, install stable baselines; only SB3 v2.0.0+ supports Gymnasium\n",
    "%pip install stable-baselines3==2.0.0 tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'width': 200,\n",
       " 'height': 200,\n",
       " 'EP_MAX_TIME': 100,\n",
       " 'seed': 666,\n",
       " 'reset_rng_episode': False,\n",
       " 'arrival': mobile_env.core.arrival.NoDeparture,\n",
       " 'channel': mobile_env.core.channels.OkumuraHata,\n",
       " 'scheduler': mobile_env.core.schedules.RoundRobin,\n",
       " 'movement': mobile_env.core.movement.RandomWaypointMovement,\n",
       " 'utility': mobile_env.core.utilities.BoundedLogUtility,\n",
       " 'handler': mobile_env.handlers.smart_city_handler.MComSmartCityHandler,\n",
       " 'bs': {'bw': 100000000.0,\n",
       "  'freq': 2500,\n",
       "  'tx': 40,\n",
       "  'height': 50,\n",
       "  'computational_power': 100},\n",
       " 'ue': {'velocity': 1.5, 'snr_tr': 2e-08, 'noise': 1e-09, 'height': 1.5},\n",
       " 'sensor': {'height': 1.5, 'snr_tr': 2e-08, 'noise': 1e-09},\n",
       " 'ue_job': {'job_generation_probability': 0.7,\n",
       "  'communication_job_lambda_value': 10.0,\n",
       "  'computation_job_lambda_value': 10.0},\n",
       " 'sensor_job': {'communication_job_lambda_value': 5.0,\n",
       "  'computation_job_lambda_value': 5.0},\n",
       " 'e2e_delay_threshold': 3.0,\n",
       " 'reward_calculation': {'ue_penalty': -5.0,\n",
       "  'discount_factor': 0.95,\n",
       "  'base_reward': 10.0,\n",
       "  'positive_discount_factor': 0.9,\n",
       "  'negative_discount_factor': 0.8},\n",
       " 'arrival_params': {'ep_time': 100, 'reset_rng_episode': False},\n",
       " 'channel_params': {},\n",
       " 'scheduler_params': {'quantum': 2.0},\n",
       " 'movement_params': {'width': 200, 'height': 200, 'reset_rng_episode': False},\n",
       " 'utility_params': {'lower': -20, 'upper': 20, 'coeffs': (10, 0, 10)},\n",
       " 'metrics': {'scalar_metrics': {},\n",
       "  'kpi_metrics': {},\n",
       "  'ue_metrics': {},\n",
       "  'bs_metrics': {},\n",
       "  'ss_metrics': {}}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import gymnasium\n",
    "import mobile_env\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "# predefined small scenarios\n",
    "from mobile_env.scenarios.smart_city import MComSmartCity\n",
    "\n",
    "# easy access to the default configuration\n",
    "MComSmartCity.default_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to results_sb/PPO_1\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 100      |\n",
      "|    ep_rew_mean     | -935     |\n",
      "| time/              |          |\n",
      "|    fps             | 58       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 35       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 100           |\n",
      "|    ep_rew_mean          | -901          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 54            |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 74            |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0057062283  |\n",
      "|    clip_fraction        | 0.0487        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.83         |\n",
      "|    explained_variance   | 3.9756298e-05 |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.31e+04      |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00773      |\n",
      "|    std                  | 0.99          |\n",
      "|    value_loss           | 2.85e+04      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -868         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 119          |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045878594 |\n",
      "|    clip_fraction        | 0.0206       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.82        |\n",
      "|    explained_variance   | 0.006268263  |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.03e+04     |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00416     |\n",
      "|    std                  | 0.988        |\n",
      "|    value_loss           | 2.31e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 100         |\n",
      "|    ep_rew_mean          | -803        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 156         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006210035 |\n",
      "|    clip_fraction        | 0.0497      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.8        |\n",
      "|    explained_variance   | 0.005253613 |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.14e+04    |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00864    |\n",
      "|    std                  | 0.974       |\n",
      "|    value_loss           | 2.12e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -750         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 52           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 195          |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071010906 |\n",
      "|    clip_fraction        | 0.0668       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.77        |\n",
      "|    explained_variance   | 0.0023412108 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.15e+03     |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0108      |\n",
      "|    std                  | 0.96         |\n",
      "|    value_loss           | 1.32e+04     |\n",
      "------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 100            |\n",
      "|    ep_rew_mean          | -670           |\n",
      "| time/                   |                |\n",
      "|    fps                  | 52             |\n",
      "|    iterations           | 6              |\n",
      "|    time_elapsed         | 236            |\n",
      "|    total_timesteps      | 12288          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0111158285   |\n",
      "|    clip_fraction        | 0.0768         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -2.71          |\n",
      "|    explained_variance   | -0.00023186207 |\n",
      "|    learning_rate        | 0.0003         |\n",
      "|    loss                 | 4.53e+03       |\n",
      "|    n_updates            | 50             |\n",
      "|    policy_gradient_loss | -0.0149        |\n",
      "|    std                  | 0.925          |\n",
      "|    value_loss           | 1.02e+04       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 100            |\n",
      "|    ep_rew_mean          | -571           |\n",
      "| time/                   |                |\n",
      "|    fps                  | 51             |\n",
      "|    iterations           | 7              |\n",
      "|    time_elapsed         | 280            |\n",
      "|    total_timesteps      | 14336          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.013425517    |\n",
      "|    clip_fraction        | 0.107          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -2.64          |\n",
      "|    explained_variance   | -0.00063860416 |\n",
      "|    learning_rate        | 0.0003         |\n",
      "|    loss                 | 4.28e+03       |\n",
      "|    n_updates            | 60             |\n",
      "|    policy_gradient_loss | -0.0177        |\n",
      "|    std                  | 0.896          |\n",
      "|    value_loss           | 7.72e+03       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 100            |\n",
      "|    ep_rew_mean          | -462           |\n",
      "| time/                   |                |\n",
      "|    fps                  | 51             |\n",
      "|    iterations           | 8              |\n",
      "|    time_elapsed         | 320            |\n",
      "|    total_timesteps      | 16384          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0066772494   |\n",
      "|    clip_fraction        | 0.0583         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -2.58          |\n",
      "|    explained_variance   | -0.00028192997 |\n",
      "|    learning_rate        | 0.0003         |\n",
      "|    loss                 | 2.04e+03       |\n",
      "|    n_updates            | 70             |\n",
      "|    policy_gradient_loss | -0.00901       |\n",
      "|    std                  | 0.879          |\n",
      "|    value_loss           | 4.59e+03       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 100            |\n",
      "|    ep_rew_mean          | -385           |\n",
      "| time/                   |                |\n",
      "|    fps                  | 50             |\n",
      "|    iterations           | 9              |\n",
      "|    time_elapsed         | 361            |\n",
      "|    total_timesteps      | 18432          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.009276375    |\n",
      "|    clip_fraction        | 0.0867         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -2.54          |\n",
      "|    explained_variance   | -0.00052678585 |\n",
      "|    learning_rate        | 0.0003         |\n",
      "|    loss                 | 956            |\n",
      "|    n_updates            | 80             |\n",
      "|    policy_gradient_loss | -0.0116        |\n",
      "|    std                  | 0.865          |\n",
      "|    value_loss           | 2.53e+03       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 100            |\n",
      "|    ep_rew_mean          | -308           |\n",
      "| time/                   |                |\n",
      "|    fps                  | 49             |\n",
      "|    iterations           | 10             |\n",
      "|    time_elapsed         | 412            |\n",
      "|    total_timesteps      | 20480          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.011276014    |\n",
      "|    clip_fraction        | 0.0973         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -2.5           |\n",
      "|    explained_variance   | -0.00071418285 |\n",
      "|    learning_rate        | 0.0003         |\n",
      "|    loss                 | 1.01e+03       |\n",
      "|    n_updates            | 90             |\n",
      "|    policy_gradient_loss | -0.0121        |\n",
      "|    std                  | 0.848          |\n",
      "|    value_loss           | 1.77e+03       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 100            |\n",
      "|    ep_rew_mean          | -229           |\n",
      "| time/                   |                |\n",
      "|    fps                  | 49             |\n",
      "|    iterations           | 11             |\n",
      "|    time_elapsed         | 457            |\n",
      "|    total_timesteps      | 22528          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.008720398    |\n",
      "|    clip_fraction        | 0.067          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -2.46          |\n",
      "|    explained_variance   | -0.00034499168 |\n",
      "|    learning_rate        | 0.0003         |\n",
      "|    loss                 | 471            |\n",
      "|    n_updates            | 100            |\n",
      "|    policy_gradient_loss | -0.00762       |\n",
      "|    std                  | 0.831          |\n",
      "|    value_loss           | 1.02e+03       |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 100            |\n",
      "|    ep_rew_mean          | -186           |\n",
      "| time/                   |                |\n",
      "|    fps                  | 49             |\n",
      "|    iterations           | 12             |\n",
      "|    time_elapsed         | 500            |\n",
      "|    total_timesteps      | 24576          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.023754247    |\n",
      "|    clip_fraction        | 0.0988         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -2.38          |\n",
      "|    explained_variance   | -0.00046789646 |\n",
      "|    learning_rate        | 0.0003         |\n",
      "|    loss                 | 454            |\n",
      "|    n_updates            | 110            |\n",
      "|    policy_gradient_loss | -0.00939       |\n",
      "|    std                  | 0.794          |\n",
      "|    value_loss           | 753            |\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 100            |\n",
      "|    ep_rew_mean          | -146           |\n",
      "| time/                   |                |\n",
      "|    fps                  | 48             |\n",
      "|    iterations           | 13             |\n",
      "|    time_elapsed         | 547            |\n",
      "|    total_timesteps      | 26624          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.015398297    |\n",
      "|    clip_fraction        | 0.0945         |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -2.34          |\n",
      "|    explained_variance   | -0.00022661686 |\n",
      "|    learning_rate        | 0.0003         |\n",
      "|    loss                 | 245            |\n",
      "|    n_updates            | 120            |\n",
      "|    policy_gradient_loss | -0.00702       |\n",
      "|    std                  | 0.785          |\n",
      "|    value_loss           | 772            |\n",
      "--------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 100          |\n",
      "|    ep_rew_mean          | -107         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 48           |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 596          |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047428375 |\n",
      "|    clip_fraction        | 0.1          |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.31        |\n",
      "|    explained_variance   | -9.36985e-05 |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 110          |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00356     |\n",
      "|    std                  | 0.792        |\n",
      "|    value_loss           | 412          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# train PPO agent on environment. this takes a while\u001b[39;00m\n\u001b[1;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m PPO(MlpPolicy, env, tensorboard_log\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults_sb\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/stable_baselines3/ppo/ppo.py:308\u001b[0m, in \u001b[0;36mPPO.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[1;32m    301\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    306\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    307\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[0;32m--> 308\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/stable_baselines3/common/on_policy_algorithm.py:259\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[0;32m--> 259\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m continue_training \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    262\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/stable_baselines3/common/on_policy_algorithm.py:178\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space, spaces\u001b[38;5;241m.\u001b[39mBox):\n\u001b[1;32m    176\u001b[0m     clipped_actions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(actions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mlow, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mhigh)\n\u001b[0;32m--> 178\u001b[0m new_obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclipped_actions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mnum_envs\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m# Give access to local variables\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:197\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \n\u001b[1;32m    193\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[0;32m--> 197\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:58\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;66;03m# Avoid circular imports\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs):\n\u001b[0;32m---> 58\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews[env_idx], terminated, truncated, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;66;03m# convert to SB3 VecEnv api\u001b[39;00m\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx] \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/stable_baselines3/common/monitor.py:94\u001b[0m, in \u001b[0;36mMonitor.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneeds_reset:\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTried to step environment that needs reset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 94\u001b[0m observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrewards\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m(reward))\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/gymnasium/wrappers/order_enforcing.py:56\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/gymnasium/wrappers/env_checker.py:49\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/mobile-env/mobile_env/core/base.py:556\u001b[0m, in \u001b[0;36mMComCore.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatarates \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m bs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstations\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m--> 556\u001b[0m     drates_ue \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstation_allocation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbw_for_ues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatarates\u001b[38;5;241m.\u001b[39mupdate(drates_ue)\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatarates_sensor \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/Documents/mobile-env/mobile_env/core/base.py:709\u001b[0m, in \u001b[0;36mMComCore.station_allocation\u001b[0;34m(self, bs, bandwidth_for_ues)\u001b[0m\n\u001b[1;32m    704\u001b[0m max_allocation \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchannel\u001b[38;5;241m.\u001b[39mdata_rate(bs, ue, snr, bandwidth_for_ues) \u001b[38;5;28;01mfor\u001b[39;00m snr, ue \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(snrs, conns)\n\u001b[1;32m    706\u001b[0m ]\n\u001b[1;32m    708\u001b[0m \u001b[38;5;66;03m# BS shares resources among connected user equipments\u001b[39;00m\n\u001b[0;32m--> 709\u001b[0m rates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshare_ue\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_allocation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbandwidth_for_ues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {(bs, ue): rate \u001b[38;5;28;01mfor\u001b[39;00m ue, rate \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(conns, rates)}\n",
      "File \u001b[0;32m~/Documents/mobile-env/mobile_env/core/schedules.py:149\u001b[0m, in \u001b[0;36mRoundRobin.share_ue\u001b[0;34m(self, bs, rates, ue_bandwidth)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshare_ue\u001b[39m(\u001b[38;5;28mself\u001b[39m, bs: BaseStation, rates: List[\u001b[38;5;28mfloat\u001b[39m], ue_bandwidth: \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[0;32m--> 149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mue_bandwidth\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/mobile-env/mobile_env/core/schedules.py:132\u001b[0m, in \u001b[0;36mRoundRobin.share\u001b[0;34m(self, bs, rates, resource)\u001b[0m\n\u001b[1;32m    130\u001b[0m     t \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquantum\n\u001b[1;32m    131\u001b[0m     allocation[i] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquantum\n\u001b[0;32m--> 132\u001b[0m     rem_rates[i] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquantum\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m     t \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m rem_rates[i]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "import gymnasium as gym\n",
    "\n",
    "env = gym.make(\"mobile-smart_city-smart_city_handler-v0\", render_mode=\"rgb_array\")\n",
    "\n",
    "# train PPO agent on environment. this takes a while\n",
    "model = PPO(MlpPolicy, env, tensorboard_log='results_sb', verbose=1)\n",
    "model.learn(total_timesteps=30000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
